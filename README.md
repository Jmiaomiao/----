1、演示视频播放链接：
https://v.youku.com/v_show/id_XNDE0OTgwNzUxNg==.html?spm=a2h3j.8428770.3416059.1
（优酷）


2、数据：

  链接：https://pan.baidu.com/s/1S90U5tumgFK2mASjYxsa5g 

提取码：071y 

复制这段内容后打开百度网盘手机App，操作更方便哦





 3、 模型：

  链接：https://pan.baidu.com/s/1PrhKGjxV5nsCHDR4jbR-Cw 

提取码：9mhu 

复制这段内容后打开百度网盘手机App，操作更方便哦


一、项目创新点与工作量
1、实现了视频动态人脸识别
在查找相关资料时，发现大多数的都为照片识别，所以在这一点上我想有所创新，将识
别静态照片转换成识别动态视频中的人物角色。
2、项目所用数据集为自己抓取并整理，非网络数据集。
3、不仅只看识别结果，还用图形可视化的方式展示出模型训练过程中的准确率。

二、总结和收获
1、python包中的example文件值得学习
在引用python的包时，可以先查看一下其中给出的example文件进行初步学习。这样相对应的编码也更加的规范化。
2、安装包的时候要注意各版本匹配
   在dlib的安装中踩了很多很多坑。在pycharm中直接安装dlib19.17.0失败，于是查
找网上教程，在cmd中通过python setup.py install安装。中间报错无数，紧接着根据教程安装cmake、MinGW等，耗时一个晚上安装完成import时依然报错。
   以为是环境问题，结果不是。后来通过anaconda prompt成功暗转dlib19.6.1版本，
在此处安装19.17.0版本依旧失败。Python为3.6版本应该没问题，各路尝试安装19.17.0版本均失败，才想到可以尝试其他版本。
3、对keras和dlib的了解和使用
   本项目尝试了老师在课上提到的keras，发现真的是易用性真的很强。创建sequential
对象并添加一些卷积、最大池化和损失层最后将它输出展平并传递给最后一个密集和损失层，然后传递到输出层。利用imagedatagenerator来增强图像，对图像进行小的转换，有助于模型更加稳定。从网上查找学习到，还可以将训练准确度等信息用图形化的形式表现出来，这样更利于分析。
   对于dlib在具体使用过程中，当人脸有较大部分遮挡时无法识别，人脸较小的时候也
无法识别。在视频中出现较远景镜头、或是光线较暗、洛基带了头盔挡住脸的轮廓时，都不能抓取视频中的人脸进行人物识别。对于人脸识别的包还需要进一步探索。
